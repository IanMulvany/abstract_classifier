{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need to try to extract training data. \n",
    "- need to create a holdout to use to test the predictions with, can be a small holdout \n",
    "- there are possibly two different patterns - files from Christine \n",
    "- files that have been added since maybe the 4th of March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from xlrd import open_workbook\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: b/: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_files = glob.glob(\"/Users/ianm/Dropbox/workbench/sage-maker-srm-test/clean-training-data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_files = glob.glob(\"/Users/ianm/Dropbox/workbench/sage-maker-srm-test/excel-data/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_from_team_member(initials, file_list):\n",
    "    team_member_files = []\n",
    "    for file in file_list:\n",
    "        tail_name = file.split(\"/\")[-1]\n",
    "        if tail_name.split()[0] == initials:\n",
    "            team_member_files.append(file)\n",
    "    return team_member_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workbook(filename):\n",
    "    wb = open_workbook(filename)\n",
    "    return wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worksheet(filename, index):\n",
    "    wb = open_workbook(filename)\n",
    "    sheet = wb.sheets()[index]\n",
    "    return sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet_names(wb):\n",
    "    return wb.sheet_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(sheet):\n",
    "    index_row = 0\n",
    "    cols = sheet.row(index_row)\n",
    "    col_names = [x.value for x in cols]\n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sheets(excel_files):\n",
    "    for excel in excel_files:\n",
    "        wb = get_workbook(excel)\n",
    "        sheets = get_sheet_names(wb)\n",
    "        print(excel.split(\"/\")[-1], sheets)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sheets_cols(excel_files):\n",
    "    for excel in excel_files:\n",
    "        wb = get_workbook(excel)\n",
    "        sheets = get_sheet_names(wb)\n",
    "        print(excel.split(\"/\")[-1])\n",
    "        for index, sheet_name in enumerate(sheets):\n",
    "            sheet = wb.sheets()[index]\n",
    "            col_names = get_col_names(sheet)\n",
    "            non_empty_col_names = list(filter(lambda x: x != '', col_names))\n",
    "            print(sheet_name, non_empty_col_names)\n",
    "            print(\"-\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the sheet and col names for our clean training\n",
    "\n",
    "all abstracts : Sheet1 / Ab \n",
    "accepted abstracts : Accepted / Abstract / Ab \n",
    "ignored : \"do not chase\", removed articles, Ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_accept = [\"Accepted\"]\n",
    "clean_training_original = [\"Sheet1\", \"Sheet 1\"]\n",
    "clean_training_ignored = [\"do not chase\", \"removed articles\", \"Ignored\"]\n",
    "abstract_col_names = [\"Ab\", \"Abstract\", \"AB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS American Journal of Industrial Medicine.xlsx\n",
      "Accepted ['C1', 'First', 'Last', 'RP', 'Email', 'Title', 'Abstract', 'Remove?', 'Journal']\n",
      "-\n",
      "Sheet 1 ['C1', 'RP', 'EM', 'TI', 'AB', 'SO']\n",
      "-\n",
      "Ignored ['[Huntley, Samuel R.; Lee, David J.; LeBlanc, William G.; Arheart, Kristopher L.; McClure, Laura A.; Fleming, Lora E.; Caban-Martinez, Alberto J.] Univ Miami, Dept Publ Hlth Sci, Miller Sch Med, 1120 NW 14th St,R-669 Clin Res Bldg,Off 1025, Miami, FL 33136 USA; [Huntley, Samuel R.] Univ Miami, Miller Sch Med, Dept Orthopaed & Rehabil, Miami Ctr Orthopaed Res & Educ CORE, Miami, FL 33136 USA; [Fleming, Lora E.] Univ Exeter, European Ctr Environm & Human Hlth, Royal Cornwall Hosp, Knowledge Spa,Med Sch, Truro, Cornwall, England', 'Alberto', 'Caban-Martinez', 'Caban-Martinez, AJ (reprint author), Univ Miami, Dept Publ Hlth Sci, Miller Sch Med, 1120 NW 14th St,R-669 Clin Res Bldg,Off 1025, Miami, FL 33136 USA.', 'acaban@med.miami.edu', 'Acute joint pain in the emerging green collar workforce: Evidence from the linked National Health Interview Survey and Occupational Information Network (O*NET)', 'Background: Green jobs are a rapidly emerging category of very heterogeneous occupations that typically involve engagement with new technologies and changing job demands predisposing them to physical stressors that may contribute to the development of joint pain. Methods: Weestimated and compared the prevalence of self-reported acute (past 30 days) joint pain between green and non-green collar workers using pooled 2004-2012 National Health Interview Survey (NHIS) data linked to the Occupational Information Network Database (O*NET). Results: Green collar workers have a higher prevalence of acute joint pain as compared to non-green collar workers. Green collar workers with pain in the upper extremity joints were significantly greater than in the non-green collar workforce, for example, right shoulder [23.2% vs 21.1%], right elbow [13.7% vs 12.0%], left shoulder [20.1% vs 18.2%], and left elbow [12.0% vs 10.7%]. Conclusions: Acute joint pain reported by the emerging green collar workforce can assist in identifying at risk worker subgroups for musculoskeletal pain interventions.', 'cs', 'American Journal of Industrial Medicine']\n",
      "-\n",
      "cs edits - dups ['C1', 'Last', 'RP', 'First', 'Email', 'Remove?', 'Title', 'Abstract', 'Journal']\n",
      "-\n",
      "removed articles ['C1', 'Last', 'RP', 'First', 'Email', 'Title', 'Abstract', 'Remove?', 'Journal']\n",
      "-\n",
      "\n",
      "MP American Journal of Hospice and Palliative Medicine.xlsx\n",
      "Accepted ['RP', 'C1', 'Firstname', 'Surname', 'Email', 'Journal', 'Title', 'AB']\n",
      "-\n",
      "Sheet1 ['PT', 'AU', 'BA', 'BE', 'GP', 'AF', 'BF', 'CA', 'TI', 'SO', 'SE', 'BS', 'LA', 'DT', 'CT', 'CY', 'CL', 'SP', 'HO', 'DE', 'ID', 'AB', 'C1', 'RP', 'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA', 'SN', 'EI', 'BN', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'PN', 'SU', 'SI', 'MA', 'BP', 'EP', 'AR', 'DI', 'D2', 'EA', 'EY', 'PG', 'WC', 'SC', 'GA', 'UT', 'PM', 'OA', 'HC', 'HP', 'DA']\n",
      "-\n",
      "\n",
      "KF Orthopaedic Journal of Sports Medicine.xlsx\n",
      "Accepted ['AF', 'first name', 'RP', 'EM', 'TI', 'AB', 'SO']\n",
      "-\n",
      "do not chase ['Feito, Yuri; Burrows, Evanette K.; Philip, Boni', '.', 'Yuri', 'Feito', 'yfeito@kennesaw.edu', 'A 4-Year Analysis of the Incidence of Injuries Among CrossFit-Trained Participants', 'Background: High-intensity functional training (HIFT) is a new training modality that merges high-intensity exercise with functional (multijoint) movements. Even though others exist, CrossFit training has emerged as the most common form of HIFT. Recently, several reports have linked CrossFit training to severe injuries and/or life-threatening conditions, such as rhabdomyolysis. Empirical evidence regarding the safety of this training modality is currently limited. Purpose: To examine the incidence of injuries related to CrossFit participation and to estimate the rate of injuries in a large cross-sectional convenience sample of CrossFit participants from around the world. Study Design: Descriptive epidemiology study. Methods: A total of 3049 participants who reported engaging in CrossFit training between 2013 and 2017 were surveyed. Results: A portion (30.5%) of the participants surveyed reported experiencing an injury over the previous 12 months because of their participation in CrossFit training. Injuries to the shoulders (39%), back (36%), knees (15%), elbows (12%), and wrists (11%) were most common for both male and female participants. The greatest number of injuries occurred among those who participated in CrossFit training 3 to 5 days per week (chi(2) = 12.51; P = .0019). Overall, and based on the assumed maximum number of workout hours per week, the injury rate was 0.27 per 1000 hours (females: 0.28; males: 0.26), whereas the assumed minimum number of workout hours per week resulted in an injury rate of 0.74 per 1000 hours (females: 0.78; males: 0.70). Conclusion: Our findings suggest that CrossFit training is relatively safe compared with more traditional training modalities. However, it seems that those within their first year of training as well as those who engage in this training modality less than 3 days per week and/or participate in less than 3 workouts per week are at a greater risk for injuries.', 'Orthopaedic Journal of Sports Medicine', ' Y (reprint author)', ' Kennesaw State Univ', ' Dept Exercise Sci & Sport Management', ' 520 Parliament Garden Way NW', 'MD 4104', ' Kennesaw', ' GA 30144 USA.']\n",
      "-\n",
      "Sheet1 ['PT', 'AU', 'BA', 'BE', 'GP', 'AF', 'BF', 'CA', 'TI', 'SO', 'SE', 'BS', 'LA', 'DT', 'CT', 'CY', 'CL', 'SP', 'HO', 'DE', 'ID', 'AB', 'C1', 'RP', 'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA', 'SN', 'EI', 'BN', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'PN', 'SU', 'SI', 'MA', 'BP', 'EP', 'AR', 'DI', 'D2', 'EA', 'EY', 'PG', 'WC', 'SC', 'GA', 'UT', 'PM', 'OA', 'HC', 'HP', 'DA']\n",
      "-\n",
      "\n",
      "KF European Journal of Orthodontics.xlsx\n",
      "Accepted ['C1', 'first name', 'last name', 'EM', 'TI', 'AB', 'SO']\n",
      "-\n",
      "Sheet1 ['PT', 'AU', 'BA', 'BE', 'GP', 'AF', 'BF', 'CA', 'TI', 'SO', 'SE', 'BS', 'LA', 'DT', 'CT', 'CY', 'CL', 'SP', 'HO', 'DE', 'ID', 'AB', 'C1', 'RP', 'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA', 'SN', 'EI', 'BN', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'PN', 'SU', 'SI', 'MA', 'BP', 'EP', 'AR', 'DI', 'D2', 'EA', 'EY', 'PG', 'WC', 'SC', 'GA', 'UT', 'PM', 'OA', 'HC', 'HP', 'DA']\n",
      "-\n",
      "\n",
      "MG Journal of Infection.xlsx\n",
      "Accepted ['C1', 'LN', 'FN', 'EM', 'AEM', 'TI', 'AB', 'SO']\n",
      "-\n",
      "Sheet1 ['PT', 'AU', 'BA', 'BE', 'GP', 'AF', 'BF', 'CA', 'TI', 'SO', 'SE', 'BS', 'LA', 'DT', 'CT', 'CY', 'CL', 'SP', 'HO', 'DE', 'ID', 'AB', 'C1', 'RP', 'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA', 'SN', 'EI', 'BN', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'PN', 'SU', 'SI', 'MA', 'BP', 'EP', 'AR', 'DI', 'D2', 'EA', 'EY', 'PG', 'WC', 'SC', 'GA', 'UT', 'PM', 'OA', 'HC', 'HP', 'DA']\n",
      "-\n",
      "\n",
      "CS Clinical Rehabilitation.xlsx\n",
      "Sheet1 ['PT', 'AU', 'BA', 'BE', 'GP', 'AF', 'BF', 'CA', 'TI', 'SO', 'SE', 'BS', 'LA', 'DT', 'CT', 'CY', 'CL', 'SP', 'HO', 'DE', 'ID', 'AB', 'C1', 'RP', 'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA', 'SN', 'EI', 'BN', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'PN', 'SU', 'SI', 'MA', 'BP', 'EP', 'AR', 'DI', 'D2', 'EA', 'EY', 'PG', 'WC', 'SC', 'GA', 'UT', 'PM', 'OA', 'HC', 'HP', 'DA']\n",
      "-\n",
      "Ignored ['[De Groef, An; Van Kampen, Marijke; Vervloesem, Nele; Dieltjens, Evi; Vos, Lore; De Vrieze, Tessa; Geraerts, Inge; Devoogdt, Nele] Univ Leuven, Dept Rehabil Sci, Leuven, Belgium; [De Groef, An; Van Kampen, Marijke; Vervloesem, Nele; Dieltjens, Evi; Vos, Lore; De Vrieze, Tessa; Geraerts, Inge; Devoogdt, Nele] Univ Hosp Leuven, Dept Phys Med & Rehabil, Herestr 49, B-3000 Leuven, Belgium; [Christiaens, Marie-Rose; Neven, Patrick] Univ Hosp Leuven, Multidisciplinary Breast Ctr, Leuven, Belgium; [Christiaens, Marie-Rose] Univ Leuven, Dept Surg Oncol, Leuven, Belgium; [Neven, Patrick] Univ Hosp Leuven, Dept Obstet & Gynaecol, Leuven, Belgium', 'De Groef, A (reprint author), Univ Hosp Leuven, Dept Phys Med & Rehabil, Herestr 49, B-3000 Leuven, Belgium.', 'an.degroef@faber.kuleuven.be', 'Effect of myofascial techniques for treatment of persistent arm pain after breast cancer treatment: randomized controlled trial', 'Objective: To investigate the effect of myofascial therapy in addition to a standard physical therapy program for treatment of persistent arm pain after finishing breast cancer treatment. Design: Double-blinded (patient and assessor) randomized controlled trial. Setting: University Hospitals Leuven, Belgium. Patients: A total of 50 patients with persistent arm pain and myofascial dysfunctions after breast cancer treatment. Intervention: Over three months, all patients received a standard physical therapy program. The intervention group received in addition 12 sessions of myofascial therapy, and the control group received 12 sessions of placebo therapy. Main measurements: Main outcome parameters were pain intensity (primary outcome) (maximum visual analogue scale (VAS) (0-100)), prevalence rate of arm pain, pressure hypersensitivity (pressure pain thresholds (kg/cm(2)) and pain quality (McGill Pain Questionnaire). Measures were taken before and after the intervention and at long term (6 and 12months follow-up). Results: Patients in the intervention group had a significantly greater decrease in pain intensity compared to the control group (VAS -44/100 vs. -24/100, P=0.046) with a mean difference in change after three months between groups of 20/100 (95% confidence interval, 0.4 to 39.7). After the intervention, 44% versus 64% of patients still experienced pain in the intervention and control group, respectively (P=0.246). No significant differences were found for the other outcomes. Conclusion: Myofascial therapy is an effective physical therapy modality to decrease pain intensity at the arm in breast cancer survivors at three months, but no other benefits at that time were found. There were no long-term effects at 12months either.', 'Clinical Rehabilitation']\n",
      "-\n",
      "Accepted ['C1', 'Reprint author', 'Last', 'First', 'Email', 'Article title', 'Remove?', 'Abstract', 'Journal']\n",
      "-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_sheets_cols(clean_training_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore structure of some of the excel fils from team members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_files = files_from_team_member(\"CS\", excel_files)\n",
    "kf_files = files_from_team_member(\"KF\", excel_files)\n",
    "mp_files = files_from_team_member(\"MP\", excel_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract column data given sheet and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sheet_names_against_validation(sheet_names, validation_list):\n",
    "    for name in sheet_names:\n",
    "        if name in validation_list: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_values_by_col_name(sheet, col_name_candidates):\n",
    "    \"\"\"\n",
    "    the assumption is that we are looking for a colum from one sheet\n",
    "    but the sheet and colum name might have one of a number of differnet values, but only one of them. \n",
    "    \"\"\"\n",
    "    col_names = get_col_names(sheet)\n",
    "    for index, col_name in enumerate(col_names):\n",
    "        if col_name in col_name_candidates:\n",
    "            col_values = sheet.col_values(index)\n",
    "            return col_values\n",
    "    return None # if we don't find the column return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_values_by_col_name_sheet_name(workbook, sheet_name_candidates, col_name_candidates):\n",
    "    \"\"\"\n",
    "    the assumption is that we are looking for a colum from one sheet\n",
    "    but the sheet and colum name might have one of a number of differnet values, but only one of them. \n",
    "    \"\"\"\n",
    "    sheet_names = get_sheet_names(workbook)\n",
    "    print(sheet_names)\n",
    "    for index, sheet_name in enumerate(sheet_names):\n",
    "        if sheet_name in sheet_name_candidates:\n",
    "            sheet = workbook.sheet_by_name(sheet_name)\n",
    "            col_values = get_col_values_by_col_name(sheet, col_name_candidates)\n",
    "            return col_values\n",
    "    return None # if we don't find the sheet, return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get col data from clean traning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_from_files_by_colname(files, col_names):\n",
    "    all_col_data = []\n",
    "    for file in files:\n",
    "        wb = get_workbook(file)\n",
    "        col_data = get_col_values_by_col_name_sheet_name(wb, col_names, abstract_col_names)\n",
    "        if col_data:\n",
    "            all_col_data.extend(col_data)\n",
    "    return all_col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accepted', 'Sheet 1', 'Ignored', 'cs edits - dups', 'removed articles']\n",
      "['Accepted', 'Sheet1']\n",
      "['Accepted', 'do not chase', 'Sheet1']\n",
      "['Accepted', 'Sheet1']\n",
      "['Accepted', 'Sheet1']\n",
      "['Sheet1', 'Ignored', 'Accepted']\n"
     ]
    }
   ],
   "source": [
    "ignored_clean_training = get_cols_from_files_by_colname(clean_training_files, clean_training_ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ignored_clean_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean_training_abstracts = get_cols_from_files_by_colname(clean_training_files, clean_training_original)\n",
    "\n",
    "accepted_clean_training = get_cols_from_files_by_colname(clean_training_files, clean_training_accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1808, 0, 1192)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_clean_training_abstracts), len(ignored_clean_training), len(accepted_clean_training) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up the \"clean\" training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1767, 1179)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_all_clean_training_abstracts = list(set(all_clean_training_abstracts))\n",
    "unique_accepted_clean_training_abstracts = list(set(accepted_clean_training))\n",
    "len(unique_all_clean_training_abstracts), len(unique_accepted_clean_training_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ones that have been rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rejected_clean_training = []\n",
    "for abstract in unique_all_clean_training_abstracts:\n",
    "    if abstract not in unique_accepted_clean_training_abstracts:\n",
    "        unique_rejected_clean_training.append(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 1179)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_rejected_clean_training), len(unique_accepted_clean_training_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'unique_rejected_clean_training' (list)\n"
     ]
    }
   ],
   "source": [
    "%store unique_rejected_clean_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'unique_accepted_clean_training_abstracts' (list)\n"
     ]
    }
   ],
   "source": [
    "%store unique_accepted_clean_training_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use abstract grabber to get abstracts from some of michaels files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_col_names = [\"AB\", \"Abstract\"]\n",
    "sheet_names_with_selections = [\"Sheet1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805\n"
     ]
    }
   ],
   "source": [
    "selection_of_michaels_selected_abstracts = []\n",
    "for file in mp_files[0:10]:\n",
    "    wb = get_workbook(file)\n",
    "    sheet_names_with_selections\n",
    "    selected_abstracts = get_col_values_by_col_name_sheet_name(wb, sheet_names_with_selections, abstract_col_names)\n",
    "    if selected_abstracts:\n",
    "        selection_of_michaels_selected_abstracts.extend(selected_abstracts)\n",
    "print(len(selection_of_michaels_selected_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'selection_of_michaels_selected_abstracts' (list)\n"
     ]
    }
   ],
   "source": [
    "%store selection_of_michaels_selected_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use abstract grabber to get abstracts from Christine's files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names_with_selections = [\"contenders\", \"to email\", \"names to check for email\", \"double articles- manual email\", \"Contenders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_col_names = [\"AB\", \"Abstract\"]\n",
    "title_col_names = [\"TI\", \"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'christine_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d0ab69bf7173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_test_abstracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_selected_abstracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchristine_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mwb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moriginal_sheet_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"original\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'christine_files' is not defined"
     ]
    }
   ],
   "source": [
    "# we do a double loop in this cell because we are looking for a selection from a sheet \n",
    "# that has accepted and rejceted abstracts \n",
    "all_test_abstracts = []\n",
    "all_selected_abstracts = []\n",
    "for file in christine_files:\n",
    "    wb = get_workbook(file)\n",
    "    original_sheet_candidates = [\"original\"]\n",
    "    original_abstracts = get_col_values_by_col_name_sheet_name(wb, original_sheet_candidates, abstract_col_names)\n",
    "    selected_abstracts = get_col_values_by_col_name_sheet_name(wb, sheet_names_with_selections, abstract_col_names)\n",
    "    if original_abstracts and selected_abstracts:\n",
    "        all_test_abstracts.extend(original_abstracts)\n",
    "        all_selected_abstracts.extend(selected_abstracts)\n",
    "        print(len(all_test_abstracts))\n",
    "        print(len(all_selected_abstracts))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n"
     ]
    }
   ],
   "source": [
    "print(len(list(set(all_selected_abstracts))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_abstracts= list(set(all_test_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_selected_abstracts = list(set(all_selected_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_abstracts = []\n",
    "for abstract in unique_abstracts:\n",
    "    if abstract not in unique_selected_abstracts:\n",
    "        rejected_abstracts.append(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n",
      "715\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_abstracts))\n",
    "print(len(unique_selected_abstracts))\n",
    "print(len(rejected_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'unique_selected_abstracts' (list)\n",
      "Stored 'rejected_abstracts' (list)\n"
     ]
    }
   ],
   "source": [
    "%store unique_selected_abstracts\n",
    "%store rejected_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scramble our lists and get our holdouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(unique_selected_abstracts)\n",
    "random.shuffle(rejected_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOLDOUT_NUMBER = 100\n",
    "holdout_selected_abstracts = unique_selected_abstracts[0:HOLDOUT_NUMBER]\n",
    "training_selected_abstracts = unique_selected_abstracts[HOLDOUT_NUMBER:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "100\n",
      "615\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_selected_abstracts))\n",
    "print(len(holdout_selected_abstracts))\n",
    "print(len(training_selected_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Unknown variable 'unique_selected_abstracts'\n"
     ]
    }
   ],
   "source": [
    "%store unique_selected_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps:  \n",
    "\n",
    "- learn about what format SAGE maker needs for training \n",
    "- work though the two lists creating a tagged set of the format that SAGE maker needs  \n",
    "- take out a 100 item set for both the selected and unselcted ones. \n",
    "- shuffle the training set  \n",
    "- send the training set to SAGE maker   \n",
    "- send the holdouts to SAGE maker to see how the model preforms  \n",
    "- repeat the above for titles "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
